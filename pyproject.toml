[project]
name = "attention-lab"
version = "1.0.0"
description = "Educational GPT implementation for understanding Transformers and attention mechanisms"
authors = [{name = "Mario Jimenez"}]
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}

dependencies = [
    "torch>=2.0.0",
    "matplotlib>=3.7.0",
    "numpy>=1.24.0",
    "tqdm>=4.65.0",
    "pyyaml>=6.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "ruff>=0.1.0",
    "mypy>=1.5.0",
    "pre-commit>=3.4.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/attention_lab"]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort
    "UP", # pyupgrade
    "B",  # flake8-bugbear
]
ignore = [
    "E501",  # line too long
]

[tool.ruff.lint.per-file-ignores]
"tests/*.py" = ["N802", "E402"]
"scripts/*.py" = ["E402"]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true
exclude = ["tests/", "scripts/"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = ["-v", "--tb=short"]

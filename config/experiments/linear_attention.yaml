# =============================================================================
# Experiment: Linear Attention (O(n) complexity)
# =============================================================================
# Test linear attention on Shakespeare

experiment:
  name: linear_attention
  seed: 42

model:
  block_size: 128  # Can handle longer sequences efficiently
  n_layer: 4
  n_head: 4
  n_embd: 128

attention:
  type: linear

training:
  max_steps: 3000
  batch_size: 32
  learning_rate: 3.0e-4
  checkpoint_dir: checkpoints/linear_attention

data:
  datasets:
    - type: shakespeare
      weight: 1.0
